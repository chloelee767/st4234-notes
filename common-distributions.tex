\documentclass{article}
\usepackage[a4paper, margin=1cm, landscape]{geometry}

\usepackage{multicol}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{hyperref}
\setlength \parindent{0pt}
\usepackage[small]{titlesec}

% \newcommand{E}{\mathbb{E}}
\begin{document}
\begin{multicols*}{3}

\section{Uniform Distribution}
\label{sec:uniform-dist}

\subsection*{Notation}

$X \sim U(a,b)$ where $-\infty < a < b < \infty$.

\subsection*{Density Function}

$f(x) = \frac{1}{b - a}$ for $x \in [a,b]$

\subsection*{Mean and Variance}

$E[X] = \frac{1}{2}(a + b)$

$Var[X] = \frac{1}{12}(b - a)^2$

\section{Binomial Distribution}
\label{sec:binom-dist}

\subsection*{Notation}

$X \sim Bin(n, p)$

\subsection*{Density Function}

$f(x) = {n \choose x} p^{x} (1-p)^{n-x}$

\subsection*{Mean and Variance}

$E(X) = np$, $Var(X) = np(1-p)$

\section{Multinomial Distribution}
\label{sec:multinomial-dist}

\subsection*{Notation}

$(X_{1},...,X_{k}) \sim Multinomial(n;p_{1},...,p_{k})$

\subsection*{Density Function}

$f(x_{1},...,x_{k}) = {n \choose x_{1},...,x_{k}} p_{1}^{x_{1}}...p_{k}^{x_{k}}$
where ${n \choose x_{1},...,x_{k}} = \frac{n!}{x_{1}! ... x_{k}!}$

\subsection*{Mean and Variance}

$E(X_{i}) = np_{i}$

$Var(X_{i}) = np_{i}(1-p_{i})$

$Cov(X_{i}X_{j}) = - n p_{i} p_{j} $ for $i \neq j$

\section{Exponential Distribution}
\label{sec:expon-dist}

Waiting time. Continuous version of geometric distribution.

\subsection*{Notation}

$X \sim Exp(1/\lambda)$

\subsection*{Density Function}

$f(x) = \lambda e^{-\lambda x}$ for $x > 0$

\subsection*{Mean and Variance}

\(E(X) = 1/\lambda\), \(Var(X) = 1/\lambda^{2}\)


\section{Beta Distribution}
\label{sec:beta-dist}

\subsection*{Notation}

$Beta(\alpha, \beta)$ where $\alpha,\beta > 0$ are the shape parameters.

\subsection*{Density Function}

$f(x) = \frac{x^{\alpha - 1} (1 - x)^{\beta - 1}}{B(\alpha,\beta)}$ where $B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$, for $x \in [0, 1]$.

\subsection*{Mean and Variance}

$E[X] = \frac{\alpha}{\alpha + \beta}$

$Var[X] = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$

\subsection*{Normal Approximation}

For sufficiently large $\alpha, \beta$, standardised $X$ is approximately $N(0,1)$.

\section{Dirichlet Distribution}
\label{sec:dirichlet-dist}

This is a multivariate generalisation of the beta distribution, hence it may also known as the multivariate beta distribution (MBD).

\subsection*{Notation}

$Dir(\alpha_{1}, \alpha_{2}, .., \alpha_{n})$ where $\alpha_{i} > 0$.

\subsection*{Density Function}

$f(x) = \frac{\Pi_{i=1}^{n} x_{i}^{\alpha_{i} - 1}}{B(\alpha_{1}, \alpha_{2}, .., \alpha_{n})}$
where $B(\alpha_{1}, \alpha_{2}, ..., \alpha_{n}) = \frac{\Gamma(\alpha_{1})\Gamma(\alpha_{2})...\Gamma(\alpha_{n})}{\Gamma(\alpha_{1} + \alpha_{2} + ... + \alpha_{n})}$

\subsection*{Mean and Variance}

$E[X_{i}] = \frac{\alpha_{i}}{\sum_{i=1}^{n} \alpha_{i}}$

$Var[X_{i}] = \frac{\tilde{\alpha}_{i}(1-\tilde{\alpha}_{i})}{\alpha_{0} + 1}$
where $\alpha_{0} = \Sigma_{i=1}^{n} \alpha_{i}$ and $\tilde{\alpha}_{i} = \alpha_{i} / \alpha_{0}$

\section{Gamma Distribution}
\label{sec:gamma-distribution}

\subsection*{Notation}

$X \sim Gamma(\alpha, 1 / \beta)$ where $\alpha, \beta > 0$

\subsection*{Density Function}

$f(x) = (\frac{\beta^{\alpha}}{\Gamma(\alpha)}) x^{\alpha-1} e^{-\beta x}$, where $\Gamma(n) = \int^{\infty}_{0} x^{\alpha-1}e^{- x} dx$.

Note that $(\frac{\lambda^{n}}{\Gamma(n)})$ is constant wrt to $x$.

\subsection*{Mean and Variance}

$E[X] = \alpha / \beta$

$Var[X] = \alpha / \beta^{2}$

\subsection*{Normal Approximation}

When $\alpha$ is large, standardised $X$ is approximately $N(0,1)$.

\section{Inverse Gamma Distribution}
\label{sec:inverse-gamma-dist}

\subsection*{Notation}

$X \sim InverseGamma(\alpha, 1 / \beta)$ where $\alpha, \beta > 0$

\subsection*{Density Function}

$f(x) = (\frac{\beta^{\alpha}}{\Gamma(\alpha)}) x^{-\alpha-1} e^{-x / \beta}$, where $\Gamma(n) = \int^{\infty}_{0} x^{\alpha-1}e^{- x} dx$.

\subsection*{Mean and Variance}

$E[X] = \frac{\beta}{\alpha - 1}$ for $\alpha > 1$

$Var[X] = \frac{\beta^{2}}{(\alpha - 1)^{2}(\alpha - 2)}$ for $\alpha > 2$

\section{Normal Distribution}
\label{sec:normal-dist}

\subsection*{Notation}

$N(\mu,\sigma^2)$ where $\mu$ is the mean, $\sigma^{2}$ is the variance

\subsection*{Density Function}

$f(x) = \frac{1}{\sqrt{2\pi}\sigma}exp\{- \frac{((x - \mu)^2)}{2\sigma^2}\}$,
$- \infty < x < \infty$.

\section{Standardised t distribution}
\label{sec:t-dist}

\subsection*{Notation}

$X \sim t_{v}$ where $v > 0$ is the degrees of freedom

\subsection*{Density Function}

$f(x) = (\frac{1}{Beta(v/2, 1/2)} \frac{1}{\sqrt{v}}) [ 1 + \frac{x^{2}}{v} ]^{-\frac{v+1}{2}}$

\subsection*{Mean and Variance}

$E(X) = 0$, $Var(X) = \frac{v}{v - 2}$

\section{Generalised t distribution}
\label{sec:general-t-dist}

\subsection*{Notation}

$X \sim t_{v}(\mu, \lambda^{-1})$ where $v > 0, \lambda > 0$.

$v$ is the degrees of freedom, $\mu$ is the location parameter and $\lambda$ is the precision parameter.

Note that $X = \mu + \lambda^{-1/2} t_{v}$

\subsection*{Density Function}

$f(x) = (\frac{1}{Beta(v/2, 1/2)} \frac{1}{\sqrt{v}}) (\lambda^{1/2}) [ 1 + \lambda \frac{(x - \mu)^{2}}{v} ]^{-\frac{v+1}{2}}$

\subsection*{Mean and Variance}

$E(X) = \mu$, $Var(X) = \frac{v}{v - 2}\lambda^{-1}$


\section{Pareto Distribution}
\label{sec:pareto-dist}

\subsection*{Notation}

$X \sim Pareto(m, a)$ where $m, a > 0$

\subsection*{Density Function}

$f(x) = \frac{am^{a}}{x^{a+1}}$ for $x \geq m$

$F(x) = [1 - (\frac{m}{a})^{a}]$ for $x \geq m$

\subsection*{Mean, Mode and Variance}

$E(X) =
\begin{cases}
  \frac{am}{a-1} & \text{for } a > 1 \\
  \infty & \text{for } a \leq 1 \\
\end{cases}
$

$Var(X) =
\begin{cases}
  \frac{am^{2}}{(a-1)^{2}(a-2)} & \text{for } a > 2 \\
  \infty & \text{for } a \leq 2 \\
\end{cases}
$

$Mode(X) = m$

\section{Poisson Distribution}
\label{sec:poisson-dist}

\subsection*{Notation}

$X \sim Poisson(\lambda)$ where $\lambda > 0$

\subsection*{Density Function}

$f(x) = e^{-\lambda} \frac{\lambda^{x}}{x!}$ for $ x = 0, 1, 2, 3, ...$

\subsection*{Mean and Variance}

$E(X) = Var(X) = \lambda$

\end{multicols*}
\end{document}
